{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-J231W9g8qS"
   },
   "source": [
    "# Converting a Custom Dataset to MEDS\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Medical-Event-Data-Standard/MEDS_ML4H_2025_Tutorial/blob/main/\n",
    "\n",
    "https://colab.research.google.com/github/Medical-Event-Data-Standard/medical-event-data-standard.github.io/blob/main/tutorial_notebooks/KDD_tutorial/Extract_a_Prediction_Task.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkBlFeUAhBM7"
   },
   "source": [
    "## Part 1: Loading the raw data\n",
    "In this tutorial, we'll use the publicly available [MIMIC-IV Demo v2.2](https://physionet.org/content/mimic-iv-demo/2.2/) dataset as our fictional \"raw data source\". Naturally, MIMIC has been used extensively in the public space, so its structure is actually very well understood and widely used; however, for the sake of this tutorial, let's act as though it isn't and we're seeing it for the first time.\n",
    "\n",
    "The first thing we need to do is load up the raw data (or, really, generally, a small random chunk of the raw data, so we can iterate quickly, though here we'll just use the entire demo dataset given its size) and take a look at it. To do that, we'll go ahead and download the raw files from PhysioNet and store them in the newly created `raw_data` directory (_note this will take some time_):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qgk7dfljcxp9"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p raw_data\n",
    "\n",
    "wget \\\n",
    "  --quiet \\\n",
    "  --no-host-directories \\\n",
    "  --recursive \\\n",
    "  --no-parent \\\n",
    "  --cut-dirs=3 \\\n",
    "  --directory-prefix \\\n",
    "  raw_data \\\n",
    "  https://physionet.org/files/mimic-iv-demo/2.2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8CKDYLXho-A"
   },
   "source": [
    "Now that the files have downloaded, what do they actually contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cDZZgHr8JZDd",
    "outputId": "30b63410-3103-41be-b583-cd15b1605525"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "bash: line 3: tree: command not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'apt-get -qq install tree > /dev/null\\n\\ntree raw_data\\n'' returned non-zero exit status 127.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbash\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapt-get -qq install tree > /dev/null\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mtree raw_data\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MEDS_ML4H_tutorial/lib/python3.14/site-packages/IPython/core/interactiveshell.py:2565\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2563\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2564\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2565\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MEDS_ML4H_tutorial/lib/python3.14/site-packages/IPython/core/magics/script.py:160\u001b[39m, in \u001b[36mScriptMagics._make_script_magic.<locals>.named_script_magic\u001b[39m\u001b[34m(line, cell)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    159\u001b[39m     line = script\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshebang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/MEDS_ML4H_tutorial/lib/python3.14/site-packages/IPython/core/magics/script.py:348\u001b[39m, in \u001b[36mScriptMagics.shebang\u001b[39m\u001b[34m(self, line, cell)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m args.raise_error \u001b[38;5;129;01mand\u001b[39;00m p.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    344\u001b[39m     \u001b[38;5;66;03m# If we get here and p.returncode is still None, we must have\u001b[39;00m\n\u001b[32m    345\u001b[39m     \u001b[38;5;66;03m# killed it but not yet seen its return code. We don't wait for it,\u001b[39;00m\n\u001b[32m    346\u001b[39m     \u001b[38;5;66;03m# in case it's stuck in uninterruptible sleep. -9 = SIGKILL\u001b[39;00m\n\u001b[32m    347\u001b[39m     rc = p.returncode \u001b[38;5;129;01mor\u001b[39;00m -\u001b[32m9\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(rc, cell)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command 'b'apt-get -qq install tree > /dev/null\\n\\ntree raw_data\\n'' returned non-zero exit status 127."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "apt-get -qq install tree > /dev/null\n",
    "\n",
    "tree raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mszQ4B9LiJuS"
   },
   "source": [
    "We can see there are a number of data files here, including:\n",
    "  - `hosp/*.csv.gz`\n",
    "  - `icu/*.csv.gz`\n",
    "\n",
    "as well as a variety of other, likely non-data files. To understand any clinical dataset, you generally should rely on both provided documentation and a _local, subject-matter expert_ who is familiar with both the _clinical and operational_ context of the dataset; however, in practice, we rarely have this. For our purposes, let's take a look at the provided [MIMIC-IV documentation](https://mimic.mit.edu/docs/iv/) to try to understand these various files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuHGxt4S2G_z"
   },
   "source": [
    "## Part 2: MEDS Extraction, conceptually\n",
    "\n",
    "For now, we'll focus on only a few files, to keep things simple (note that each file below links to its specific data source documentation):\n",
    "\n",
    "  1. [`hosp/patients.csv.gz`](https://mimic.mit.edu/docs/iv/modules/hosp/patients)\n",
    "  2. [`hosp/admissions.csv.gz`](https://mimic.mit.edu/docs/iv/modules/hosp/admissions)\n",
    "  3. [`hosp/procedures_icd.csv.gz`](https://mimic.mit.edu/docs/iv/modules/hosp/procedures_icd)\n",
    "  4. [`icu/icustays.csv.gz`](https://mimic.mit.edu/docs/iv/modules/icu/icustays)\n",
    "  5. [`icu/chartevents.csv.gz`](https://mimic.mit.edu/docs/iv/modules/icu/chartevents)\n",
    "\n",
    "To start understanding how we should think about extracting a MEDS view of this data, let's inspect some of the data using [pandas](https://pandas.pydata.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 634
    },
    "id": "XcJ6Qa5HiFVH",
    "outputId": "147aa260-aadf-4108-a937-c4d25efd97f0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ROOT = Path(\"raw_data\")\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for fn in [\n",
    "    \"hosp/patients.csv.gz\",\n",
    "    \"hosp/admissions.csv.gz\",\n",
    "    \"hosp/procedures_icd.csv.gz\",\n",
    "    \"icu/icustays.csv.gz\",\n",
    "    \"icu/chartevents.csv.gz\",\n",
    "]:\n",
    "  fp = DATA_ROOT / fn\n",
    "  df = pd.read_csv(fp)\n",
    "  print(f\"{fn}:\")\n",
    "  display(df.head(2))\n",
    "  dfs[fn.split(\".\")[0]] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDGE9rrXkNu_"
   },
   "source": [
    "We can see there is a _lot_ of data contained in just these files! How can we hope to go about unifying it all into the simple MEDS format in a reasonable time?\n",
    "\n",
    "To do so, we'll follow the assumptions of the MEDS-Extract library, which organizes the mapping of EHR data elements into the MEDS format via the following questions. For each row of each input source, we ask\n",
    "  1. What is happening in this row?\n",
    "  2. To whom is it happening?\n",
    "  3. When is it happening?\n",
    "\n",
    "Once we can answer each of these three questions, we're ready to extract a full MEDS dataset over our inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiSlIyVY2Yn7"
   },
   "source": [
    "### Part 2.1 Mapping the `hosp/patients` table\n",
    "\n",
    "To see these in action, let's work through our files in order, starting with `hosp/patients.csv.gz`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "JjwSvMnyj8w5",
    "outputId": "5dbeb8ae-0af1-48d0-faf8-fe9d2ee78f63"
   },
   "outputs": [],
   "source": [
    "dfs['hosp/patients'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VV-iQhyfM8lF"
   },
   "source": [
    "We can see that this dataframe clearly captures some static data about the patients in the population, any external date-of-death information present about the subject, and meta-data about how this subject's data is transformed when included in MIMIC via the [anchor year group](https://mimic.mit.edu/docs/iv/modules/hosp/patients/#anchor_age-anchor_year-anchor_year_group). The latter aspect won't feature ino the MEDS representation, so this means we only have the following pieces of information to represent about the patient:\n",
    "  1. The information in the `gender` column, which for this dataset we will assign to a static measurement given if is recorded as sudh within the raw dataset.\n",
    "  2. The information in the `anchor_age` column indicating the patient's date of birth (after some transformation).\n",
    "  3. The information in the `dod` column, which [contains a de-identified date of death for the patient](https://mimic.mit.edu/docs/iv/modules/hosp/patients/#dod), if applicable.\n",
    "\n",
    "Ultimately, this tells us that for each row of the `hosp/patients` table, we'll want to construct 3 MEDS events:\n",
    "  1. A measurement for subject `subject_id` with a `null` timestamp with a code indicating the value in the `gender` column.\n",
    "  2. A measurement for subject `subject_id` with a timestamp given by the `dod` column (if it is not null) and the `MEDS_DEATH` code (as this is a death event) and no values.\n",
    "  3. A measurement for subject `subject_id` with a timestamp given by the difference between the `anchor_year` and the `anchor_age`, converted to a date-time, with the `MEDS_BIRTH` code and no values.\n",
    "\n",
    "Let's record the information for these events in a simple, declarative format that we'll encode in [YAML](https://yaml.org/). For now, just think of this as an _approximate_ format -- it isn't technically precise just yet. But, as we build up our specification, we'll see how we can turn it into a complete description of the extraction process. In particular, we'll have an outer level of the YAML correspond to the file we're talking about (in this case `hosp/patients`) and then we'll have an inner block for each of the 3 events we've identified, describing what columns they'll use for to construct their timestamps and codes (we don't have values for any of these events, but we'll add them in later).\n",
    "\n",
    "Specification so far:\n",
    "```yaml\n",
    "hosp/patients:\n",
    "  gender:\n",
    "    subject_id: subject_id\n",
    "    code: gender\n",
    "    time: null\n",
    "  death:\n",
    "    subject_id: subject_id\n",
    "    code: MEDS_DEATH\n",
    "    time: dod @ 11:59 p.m.\n",
    "  birth:\n",
    "    subject_id: subject_id\n",
    "    code: MEDS_BIRTH\n",
    "    time: anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou-hCukVUiE_"
   },
   "source": [
    "**Note:** Note that the `patients` table has already revealed two common complications when converting clinical data (to any format, not just MEDS):\n",
    "  1. The `dod` column only provides a _date_ level resolution, not a time level resolution. This means that we don't know whether or not the patient died at 12:01 a.m. on that date or at 11:59 p.m. on that date, despite these two times being separated by nearly 24 full hours! This can cause issues with measurement ordering, the validity of temporal prediction tasks (e.g., predicting imminent mortality), etc. Ultimately, _some choice_ needs to be made in how we want to represent this in MEDS. By design, MEDS does not allow you to specify a date-only timestamp, as such a timestamp does not permit a total ordering of measurements across different events. Here, as we know that death is a final event and is often (if not universally) the last event recorded for the patient, it makes sense to place it at the _latest possible time_ within that date (i.e., add an implicit 11:59:59 p.m. onto the end of that timestamp column).\n",
    "  2. As this dataset records an \"age\" (via `anchor_age`) rather than an explicit date of birth, we have a similar, but even greater lack of temporal resolution in the date of birth column of the data. Here, we need to choose when within that year we should assign the patient's date of birth; again, there is no \"right\" answer, but we need to make a choice. For this event, we'll choose January 1st of that year, to keep things simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VykDtBZ92grl"
   },
   "source": [
    "### Part 2.2: The `hosp/admissions` table:\n",
    "\n",
    "Next, let's inspect the `admissions` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "QvPAjNJiLtoZ",
    "outputId": "7c8a25c6-7f88-4984-b4b5-065cf07daa92"
   },
   "outputs": [],
   "source": [
    "dfs['hosp/admissions'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp7n1OKgSY_N"
   },
   "source": [
    "Here, we have a lot of additional pieces of data -- records of admissions, discharges, possible competing records of deaths, admission types, locations for both admissions and discharges, patient information at time of admission (e.g., insurance, language, marital status, race), and emergency department (`ed`*) registration & discharge information. One new piece of complexity here that is worth noting is that many of these events are \"interval\" style events -- namely, events that present with both a start and an end time (e.g., an admission and discharge, an ED registration and an ED out, etc.). The \"MEDS way\" to handle such events is to simply include both a separate, appropriately timed start event and an end event -- that way you are representing each interaction separately in its appropriate place in the patient timeline. This comes through naturally when we focus on asking our three questions from above. With this perspective, we can quickly identify a list of measurements these columns represent:\n",
    "  1. There is (or may be, if the timestamp is not null) a \"hospital admission\" of type `admission_type` to location `admission_location` at the time given by `admittime` for the subject given in `subject_id` (_Note we are not tracking the `admit_provider_id` as MEDS does not currently formalize the notion of the treating provider_).\n",
    "  2. At the time of the hospital admission, some [patient demographics](https://mimic.mit.edu/docs/iv/modules/hosp/admissions/#insurance-language-marital_status-ethnicity) are collected about `subject_id`, including their:\n",
    "    - `insurance`\n",
    "    - `language`\n",
    "    - `marital_status`\n",
    "    - `race`\n",
    "  3. There may be a \"hospital discharge\" to the location `discharge_location` at time `dischtime` for `subject_id`.\n",
    "  4. There may be a \"death\" event at time `deathtime` for `subject_id`.\n",
    "  5. There may be an \"ED Registration\" event at time `edregtime` for `subject_id`.\n",
    "  6. There may be an \"ED Out\" event at time `edouttime` for `subject_id`.\n",
    "\n",
    "Given these event descriptions, we can update our specification as follows:\n",
    "\n",
    "```yaml\n",
    "hosp/patients:\n",
    "  gender:\n",
    "    subject_id: subject_id\n",
    "    code: gender\n",
    "    time: null\n",
    "  death:\n",
    "    subject_id: subject_id\n",
    "    code: MEDS_DEATH\n",
    "    time: dod @ 11:59 p.m.\n",
    "  birth:\n",
    "    subject_id: subject_id\n",
    "    code: MEDS_BIRTH\n",
    "    time: anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "\n",
    "hosp/admissions:\n",
    "  admission:\n",
    "    subject_id: subject_id\n",
    "    code: \"HOSPITAL_ADMISSION//${admission_type}//${admission_location}\"\n",
    "    time: admittime\n",
    "  language:\n",
    "    subject_id: subject_id\n",
    "    code: \"LANGUAGE//${language}\"\n",
    "    time: admittime\n",
    "  marital_status:\n",
    "    subject_id: subject_id\n",
    "    code: \"MARITAL_STATUS//${marital_status}\"\n",
    "    time: admittime\n",
    "  insurance:\n",
    "    subject_id: subject_id\n",
    "    code: \"INSURANCE//${insurance}\"\n",
    "    time: admittime\n",
    "  race:\n",
    "    subject_id: subject_id\n",
    "    code: \"RACE//${race}\"\n",
    "    time: admittime\n",
    "  discharge:\n",
    "    subject_id: subject_id\n",
    "    code: \"HOSPITAL_DISCHARGE//${discharge_location}\"\n",
    "    time: dischtime\n",
    "  death:\n",
    "    subject_id: subject_id\n",
    "    code: MEDS_DEATH\n",
    "    time: deathtime\n",
    "  ed_reg:\n",
    "    subject_id: subject_id\n",
    "    code: ED_REGISTRATION\n",
    "    time: edregtime\n",
    "  ed_out:\n",
    "    subject_id: subject_id\n",
    "    code: ED_OUT\n",
    "    time: edouttime\n",
    "```\n",
    "\n",
    "\n",
    "_Heads up that we're being a bit imprecise with our syntax here, as this is just (for now) a mental aid -- namely, we're using some plain strings to represent column names (e.g., `code: gender` and `subject_id: subject_id`) and sometimes we're using strings explicitly indicated with double-quotes to indicate compound codes using python's string interpolation syntax (e.g., `code: \"HOSPITAL_DISCHARGE//${discharge_location}\"). We'll formalize this later, but for now, use context to disambiguate which we mean._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPkH2sOqi9cu"
   },
   "source": [
    "Note that, much like before we've seen some other areas where challenges arise and assumptions need to be made in mapping this table:\n",
    "\n",
    "1. **Multifactorial measurements**: Here, there are several measurements that come with different parts. We have admissions occurring with types and to locations alongside demographic data being measured like language, marital status, race, and insurance type. How should we map all of these to a set of distinct measurements with what codes? In general, this question comes down to a trade-off between _more simultaneous measurements_ vs. _more complex codes_ -- i.e., you can either produce more measurements for each distinct aspect of the code at the same time-point, or you can add more pieces of information into a single code string, thereby increasing the size of your vocabulary. This data extraction step shows both strategies in action, for good reason:\n",
    "\n",
    "  - For admission type and location, we include them in the core hospital admission code. This makes sense because _every admission has to have a type and a location_ -- so they are natural \"modifiers\" to the admission measurement conceptually, as opposed to being distinct measurements. We'd also almost never have a situation where a model would need to know that an admission happened, but not know of what type or to where.\n",
    "\n",
    "  - On the other hand, for the patient demographic information, these have each been separated into distinct measurements all at the same point in time -- each aspect of the demographic data is thus recorded separately, so if we wish to later filter out rare or unknown recordings for one aspect of the demographic data in isolation of the others, this will be easy to do at a measurement level. Ultimately, however, it may also be reasonable (or even work better in some modeling tasks) to instead have produced a joint code string across all demographic information (e.g., `LANGUAGE//${language}//INSURANCE//${insurance}//...`). If you want to try that out yourself, let us know if it works better!\n",
    "\n",
    "  The existence of these multifactorial codes also highlights a convention we'll take in this guide, which is to compose \"structured code strings\" using the double-slash (`\"//\"`) as a separator, as this is unlikely to occur in a raw code string. This is not a formal requirement, so feel free to use a different approach in your data -- but what is important to note is that you likely do not want code strings to collide across different measurement sources. So, if you just used `code: race` and `code: language`, for example, and `UNK` was an option for both `race` and `language`, your model's wouldn't be able to differentiate between those two options unless you use a unique prefix (like we do here).\n",
    "  \n",
    "2. **Competing Measurement Sources**: There's _another_ death time in this file, in addition to the `dod` recorded in the `patients` table! This is, unfortunately, a common enough problem in EHR data. Luckily, its solution is pretty straightforward -- simply decide which source has precedent (ideally this will be a universal property, not a data-dependent one) and favor that over the other. Here, as the `deathtime` in this dataset has full datetime resolution, it will be preferred over the `dod` in the other file. We'll merely denote that with a comment in our specification for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s73ZeoTfk8_2"
   },
   "source": [
    "At this point, our specification is also getting pretty verbose. Let's pull out the shared aspects across all event blocks into the upper level categories -- for now this just includes the `subject_id` specification -- so we can get rid of some wasted space:\n",
    "\n",
    "```yaml\n",
    "subject_id: subject_id\n",
    "hosp/patients:\n",
    "  gender:\n",
    "    code: gender\n",
    "    time: null\n",
    "  death: # Superceded by the `death` measurement in hosp/admissions\n",
    "    code: MEDS_DEATH\n",
    "    time: dod @ 11:59 p.m.\n",
    "  birth:\n",
    "    code: MEDS_BIRTH\n",
    "    time: anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "\n",
    "hosp/admissions:\n",
    "  admission:\n",
    "    code: \"HOSPITAL_ADMISSION//${admission_type}//${admission_location}\"\n",
    "    time: admittime\n",
    "  language:\n",
    "    code: \"LANGUAGE//${language}\"\n",
    "    time: admittime\n",
    "  marital_status:\n",
    "    code: \"MARITAL_STATUS//${marital_status}\"\n",
    "    time: admittime\n",
    "  insurance:\n",
    "    code: \"INSURANCE//${insurance}\"\n",
    "    time: admittime\n",
    "  race:\n",
    "    code: \"RACE//${race}\"\n",
    "    time: admittime\n",
    "  discharge:\n",
    "    code: \"HOSPITAL_DISCHARGE//${discharge_location}\"\n",
    "    time: dischtime\n",
    "  death: # Takes precedent over the `death` measurement in hosp/patients\n",
    "    code: MEDS_DEATH\n",
    "    time: deathtime\n",
    "  ed_reg:\n",
    "    code: ED_REGISTRATION\n",
    "    time: edregtime\n",
    "  ed_out:\n",
    "    code: ED_OUT\n",
    "    time: edouttime\n",
    "```\n",
    "\n",
    "While there are other ways we could further condense this (e.g., using a list of objects rather than a dictionary of objects within each data source) that will hurt us more on clarity, so we'll keep that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdbKuGs9lkko"
   },
   "source": [
    "### Part 2.3: The `hosp/procedures_icd` table\n",
    "\n",
    "Let's move onto our next table: `procedures_icd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "NfAkawGAPYCP",
    "outputId": "db0e2f21-d09e-4ee4-9b0e-00ef6af9f1e6"
   },
   "outputs": [],
   "source": [
    "dfs['hosp/procedures_icd'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKIAJ6YCmTnM"
   },
   "source": [
    "Here, we have a bit of an easier time -- there's clearly only one measurement being recorded here -- the ICD code itself, recorded for `subject_id` at the time given by `chartdate`. However, much like for the `dod` column in the `hosp/patients` table, this is only a date, not a full datetime, so we need to decide at what timestamp within the date we should assign this. Here, the situation is not quite so simple; unlike death, which is clearly a \"final\" event, procedures can happen throughout the day, and we don't know where it would be best to assign the recordings of their ICD codes. Ultimately, as we are more likely to want to predict things that are based on these procedures or heavily indicated by these procedures, it is better to put them later in the day rather than earlier to avoid temporal leakage -- though note that this can still cause leakage in tasks that are attempting to predict these procedure codes themselves! Regardless, we'll assign them the time of 11:59:59 p.m. on the given day here. We'll also want to ensure we capture both the `icd_code` and `icd_version` in these measurements, as both are necessary to fully define the assigned ICD code.\n",
    "\n",
    "Before we show our new specification, note that there is one additional complexity here we should take into account, and that is [`seq_num`](https://mimic.mit.edu/docs/iv/modules/hosp/procedures_icd/#seq_num). This is actually an important piece of information, as it indicates the relative prioritization of the given codes assigned to the patient (a lower `seq_num` indicating a higher priority code). This is a common paradigm for diagnostic codes in U.S. healthcare datasets, so we do want to include it; however, it doesn't feel quite right to include it in the code as it is not a real part of the measurement about the patient. Instead, for this example, we'll use the fact that MEDS datasets are permitted to include any other desired columns beyond the required columns, so we can just track it directly as an external column:\n",
    "\n",
    "```yaml\n",
    "subject_id: subject_id\n",
    "hosp/patients:\n",
    "  gender:\n",
    "    code: gender\n",
    "    time: null\n",
    "  death: # Superceded by the `death` measurement in hosp/admissions\n",
    "    code: MEDS_DEATH\n",
    "    time: dod @ 11:59 p.m.\n",
    "  birth:\n",
    "    code: MEDS_BIRTH\n",
    "    time: anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "\n",
    "hosp/admissions:\n",
    "  admission:\n",
    "    code: \"HOSPITAL_ADMISSION//${admission_type}//${admission_location}\"\n",
    "    time: admittime\n",
    "  language:\n",
    "    code: \"LANGUAGE//${language}\"\n",
    "    time: admittime\n",
    "  marital_status:\n",
    "    code: \"MARITAL_STATUS//${marital_status}\"\n",
    "    time: admittime\n",
    "  insurance:\n",
    "    code: \"INSURANCE//${insurance}\"\n",
    "    time: admittime\n",
    "  race:\n",
    "    code: \"RACE//${race}\"\n",
    "    time: admittime\n",
    "  discharge:\n",
    "    code: \"HOSPITAL_DISCHARGE//${discharge_location}\"\n",
    "    time: dischtime\n",
    "  death: # Takes precedent over the `death` measurement in hosp/patients\n",
    "    code: MEDS_DEATH\n",
    "    time: deathtime\n",
    "  ed_reg:\n",
    "    code: ED_REGISTRATION\n",
    "    time: edregtime\n",
    "  ed_out:\n",
    "    code: ED_OUT\n",
    "    time: edouttime\n",
    "\n",
    "hosp/procedures_icd:\n",
    "  procedure_icd:\n",
    "    code: \"PROCEDURE//ICD${icd_version}//${icd_code}\"\n",
    "    time: chartdate @ 11:59 p.m.\n",
    "    seq_num: seq_num\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DBxKDSFpq4L"
   },
   "source": [
    "### Part 2.4: The `icu/icustays` table\n",
    "Now, let's look at `icustays`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "o5jfaxLWmQC3",
    "outputId": "b4929a8d-5a3e-49b3-d3c4-357268d6b27c"
   },
   "outputs": [],
   "source": [
    "dfs['icu/icustays'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxpNNOX6qJYZ"
   },
   "source": [
    "This table is much like the `hosp/admissions` table -- we have some \"interval\" style events being recorded here (namely, ICU stays) which we'll separate into endpoints, resulting in:\n",
    "  1. An ICU admission event for `subject_id` at `intime` to the `first_careunit`\n",
    "  2. An ICU discharge event for `subject_id` at `outtime` from the `last_careunit`.\n",
    "\n",
    "Note two things:\n",
    "  - The `los` here is actually a _derived_ property -- it isn't something we want to record in the MEDS data directly (especially not in the ICU admission event because that could risk future leakage).\n",
    "  - We're actually being a bit inconsistent here -- really, we should likely try to find another table in the MIMIC source which captures the sequence of careunits the patient is seen within so that we can record transfers _to a careunit_ universally, rather than having an ICU admission _to a careunit_ and an ICU discharge _from a careunit_ -- but for now, this is outside the scope of our tutorial (but if you're interested, the right table to use for this is the [`hosp/transfers`](https://mimic.mit.edu/docs/iv/modules/hosp/transfers/) table, which is actually the [ground truth source for the `icu/icustays` table](https://mimic.mit.edu/docs/iv/modules/hosp/transfers/#important-considerations).).\n",
    "\n",
    "When we add this to our spec, we obtain:\n",
    "\n",
    "```yaml\n",
    "subject_id: subject_id\n",
    "hosp/patients:\n",
    "  gender:\n",
    "    code: gender\n",
    "    time: null\n",
    "  death: # Superceded by the `death` measurement in hosp/admissions\n",
    "    code: MEDS_DEATH\n",
    "    time: dod @ 11:59 p.m.\n",
    "  birth:\n",
    "    code: MEDS_BIRTH\n",
    "    time: anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "\n",
    "hosp/admissions:\n",
    "  admission:\n",
    "    code: \"HOSPITAL_ADMISSION//${admission_type}//${admission_location}\"\n",
    "    time: admittime\n",
    "  language:\n",
    "    code: \"LANGUAGE//${language}\"\n",
    "    time: admittime\n",
    "  marital_status:\n",
    "    code: \"MARITAL_STATUS//${marital_status}\"\n",
    "    time: admittime\n",
    "  insurance:\n",
    "    code: \"INSURANCE//${insurance}\"\n",
    "    time: admittime\n",
    "  race:\n",
    "    code: \"RACE//${race}\"\n",
    "    time: admittime\n",
    "  discharge:\n",
    "    code: \"HOSPITAL_DISCHARGE//${discharge_location}\"\n",
    "    time: dischtime\n",
    "  death: # Takes precedent over the `death` measurement in hosp/patients\n",
    "    code: MEDS_DEATH\n",
    "    time: deathtime\n",
    "  ed_reg:\n",
    "    code: ED_REGISTRATION\n",
    "    time: edregtime\n",
    "  ed_out:\n",
    "    code: ED_OUT\n",
    "    time: edouttime\n",
    "\n",
    "hosp/procedures_icd:\n",
    "  procedure_icd:\n",
    "    code: \"PROCEDURE//ICD${icd_version}//${icd_code}\"\n",
    "    time: chartdate @ 11:59 p.m.\n",
    "    seq_num: seq_num\n",
    "\n",
    "icu/icustays:\n",
    "  admission:\n",
    "    code: \"ICU_ADMISSION//${first_careunit}\"\n",
    "    time: intime\n",
    "  discharge:\n",
    "    code: \"ICU_DISCHARGE//${last_careunit}\"\n",
    "    time: outtime\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQPuRAugp1Jq"
   },
   "source": [
    "### Part 2.5: `icu/chartevents`:\n",
    "Finally, let's look at `chartevents`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "JdTvqB63pt-N",
    "outputId": "8f2cfe1a-0106-444d-9887-1001137d7bf3"
   },
   "outputs": [],
   "source": [
    "dfs['icu/chartevents'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ob_omu3ivYM-"
   },
   "source": [
    "This table clearly has rows that capture a variety of recordings of some more nuanced measurements. Some have numerical results, units of measure, etc. We also have another complexity here in that we have some uncertainty in timestamp, with both `charttime` and `storetime` being included. Ultimately, though, there is still just one kind of measurement being recorded here: Namely, a \"chart event\" (often a lab test), identified via the \"Item ID\" `itemid` being recorded at either `charttime` or `storetime`, with a value given by the columns within `value`, `valuenum`, and `valueuom`. Let's see how to add that to our specification (for brevity, we'll just show the new bit first, before we put it all together):\n",
    "\n",
    "```yaml\n",
    "icu/chartevents:\n",
    "  chartevent:\n",
    "    time: charttime\n",
    "    code: \"CHARTEVENT//${itemid}//${valueuom}\"\n",
    "    numeric_value: valuenum\n",
    "```\n",
    "\n",
    "Note here that we've made a few assumptions:\n",
    "  1. We've defaulted to favor `charttime` here -- this is because, according to the [data documentation](https://mimic.mit.edu/docs/iv/modules/icu/chartevents/#charttime-storetime), `charttime` is the closest proxy to when the data was actually recorded. However, this could benefit from further investigation and empirical validation!\n",
    "  2. We are omitting the `warning` column -- this is because we don't know when a warning would actually have been noted by the care-team, as it does not represent an automated process as part of the chart event measurement, but rather [is a manual observation by the care team after the data has been recorded](https://mimic.mit.edu/docs/iv/modules/icu/chartevents/#warning)\n",
    "  \n",
    "In addition, this format has the following undesired property -- if `valueuom` is empty or `NaN`, the code string will have a trailing `//` (because we've included `valueuom` in the template, even though it will only be used for things with a numeric measurement). We can try to remedy this later, though it is not a high-priority issue as it only results in a superficial change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xM68mSEn1p3y"
   },
   "source": [
    "All told, this gives us a final \"specification\" for the data extraction (at a conceptual level) as follows:\n",
    "\n",
    "```yaml\n",
    "subject_id: subject_id\n",
    "hosp/patients:\n",
    "  gender:\n",
    "    code: gender\n",
    "    time: null\n",
    "  death: # Superceded by the `death` measurement in hosp/admissions\n",
    "    code: MEDS_DEATH\n",
    "    time: dod @ 11:59 p.m.\n",
    "  birth:\n",
    "    code: MEDS_BIRTH\n",
    "    time: anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "\n",
    "hosp/admissions:\n",
    "  admission:\n",
    "    code: \"HOSPITAL_ADMISSION//${admission_type}//${admission_location}\"\n",
    "    time: admittime\n",
    "  language:\n",
    "    code: \"LANGUAGE//${language}\"\n",
    "    time: admittime\n",
    "  marital_status:\n",
    "    code: \"MARITAL_STATUS//${marital_status}\"\n",
    "    time: admittime\n",
    "  insurance:\n",
    "    code: \"INSURANCE//${insurance}\"\n",
    "    time: admittime\n",
    "  race:\n",
    "    code: \"RACE//${race}\"\n",
    "    time: admittime\n",
    "  discharge:\n",
    "    code: \"HOSPITAL_DISCHARGE//${discharge_location}\"\n",
    "    time: dischtime\n",
    "  death: # Takes precedent over the `death` measurement in hosp/patients\n",
    "    code: MEDS_DEATH\n",
    "    time: deathtime\n",
    "  ed_reg:\n",
    "    code: ED_REGISTRATION\n",
    "    time: edregtime\n",
    "  ed_out:\n",
    "    code: ED_OUT\n",
    "    time: edouttime\n",
    "\n",
    "hosp/procedures_icd:\n",
    "  procedure_icd:\n",
    "    code: \"PROCEDURE//ICD${icd_version}//${icd_code}\"\n",
    "    time: chartdate @ 11:59 p.m.\n",
    "    seq_num: seq_num\n",
    "\n",
    "icu/icustays:\n",
    "  admission:\n",
    "    code: \"ICU_ADMISSION//${first_careunit}\"\n",
    "    time: intime\n",
    "  discharge:\n",
    "    code: \"ICU_DISCHARGE//${last_careunit}\"\n",
    "    time: outtime\n",
    "\n",
    "icu/chartevents:\n",
    "  chartevent:\n",
    "    time: charttime\n",
    "    code: \"CHARTEVENT//${itemid}//${valueuom}\"\n",
    "    numeric_value: valuenum\n",
    "```\n",
    "\n",
    "Then, our question becomes, how can we use this model to actually extract the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5BFYyBk23vA"
   },
   "source": [
    "## Part 3: Using MEDS-Extract to Automate Extraction\n",
    "\n",
    "So far, all we've built up is a _conceptual_ map on how to think about extracting data to MEDS. Hopefully, in doing so, you've come to see how the _simplicity_ of MEDS gives rise to likewise simple extraction pipelines -- rather than requiring hours or days to understand the various input files, you can often map the rows of input tables into a conceptual specification for MEDS extraction in minutes, even when presented with more complex cases that require some assumptions to be made.\n",
    "\n",
    "However, as it turns out, not only is this conceptual specification useful theoretically, it also is very close to a precise technical specification that the MEDS-Extract package can use to extract your data in the MEDS format for you.\n",
    "\n",
    "The MEDS-Extract library leverages [MEDS-Transforms](https://github.com/mmcdermott/MEDS_transforms) to run a full ETL pipeline, with the secret sauce in the middle being the \"MEDS-Extract Specification Syntax YAML\" (MESSY) file -- which tells you how to map your messy input data into the MEDS format in alignment with this conceptual model.\n",
    "\n",
    "This file is (as the name implies) in the YAML format and looks much like our specification above. It consists of blocks mapping input source table name to named measurements within the rows of that table, each measurement block having some sentinel properties which map to a prescribed extraction syntax that controls how the input data is parsed. It does, unfortunately, have some limitations that will make certain operations in our conceptual specification a bit harder. Let's dig in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yi8AUyBz5f0"
   },
   "source": [
    "### The MESSY File Format\n",
    "\n",
    "#### 1. The Outer Structure\n",
    "First, much like our conceptual specification above, the MESSY file will have a block per input source, within which we'll go through and identify all the measurements we want to extract from that source. In this case, that means we'll have a block for each of the tables we've listed above:\n",
    "\n",
    "```yaml\n",
    "hosp/patients:\n",
    "  ...\n",
    "hosp/admissions:\n",
    "  ...\n",
    "hosp/procedures_icd:\n",
    "  ...\n",
    "icu/icustays:\n",
    "  ...\n",
    "icu/chartevents:\n",
    "  ...\n",
    "```\n",
    "\n",
    "Also, much like our specification above, we can specify _shared properties_ at the top level -- so we can add back in our `subject_id` indicator as well, though in the MESSY format, we need to name it `subject_id_col` (for no particularly good reason):\n",
    "\n",
    "```yaml\n",
    "subject_id_col: subject_id\n",
    "hosp/patients:\n",
    "  ...\n",
    "hosp/admissions:\n",
    "  ...\n",
    "hosp/procedures_icd:\n",
    "  ...\n",
    "icu/icustays:\n",
    "  ...\n",
    "icu/chartevents:\n",
    "  ...\n",
    "```\n",
    "\n",
    "#### 2. Measurement blocks\n",
    "Within each table source, we also need to specify all of the measurements we want to extract. Again, our format will look pretty similar, but a bit different. Our conceptual specification had measurements that looked like each of the following prototypical examples:\n",
    "\n",
    "```yaml\n",
    "gender:\n",
    "  code: gender\n",
    "  time: null\n",
    "death:\n",
    "  code: MEDS_DEATH\n",
    "  time: dod @ 11:59 p.m.\n",
    "birth:\n",
    "  code: MEDS_BIRTH\n",
    "  time: anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "admission:\n",
    "  code: \"HOSPITAL_ADMISSION//${admission_type}//${admission_location}\"\n",
    "  time: admittime\n",
    "death:\n",
    "  code: MEDS_DEATH\n",
    "  time: deathtime\n",
    "procedure_icd:\n",
    "  code: \"PROCEDURE//ICD${icd_version}//${icd_code}\"\n",
    "  time: chartdate @ 11:59 p.m.\n",
    "  seq_num: seq_num\n",
    "chartevent:\n",
    "  time: charttime\n",
    "  code: \"CHARTEVENT//${itemid}//${valueuom}\"\n",
    "  numeric_value: valuenum\n",
    "```\n",
    "\n",
    "Let's walk through each to see which features we'll need to change:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2KPeTtr6oiR"
   },
   "source": [
    "##### **Specifying Time Format Strings**\n",
    "A key missing piecce here is that we've indicated some strings are \"time\" columns, but we're not saying how those should be parsed from the (string) input types accessible in our CSV files! While this is not an issue if our inputs were parquets or something else with typed timestamp columns, for CSVs we need to address it. Luckily, this is simple; we can just add a `time_format` key to each block with a time format string used to parse the column. Refer to the [chrono crate](https://docs.rs/chrono/latest/chrono/format/strftime/index.html) documentation for how these format strings should be specified. In this case, we want the following format string for most use cases: `time_format: \"%Y-%m-%d %H:%M:%S\"`.\n",
    "\n",
    "What if a column isn't so nicely formatted, and there are multiple format strings in the data? You can also specify a list of format strings to the `time_format` key, and they will be used in specified order until one works on a given input for that column; e.g., `time_format: [\"%Y-%m-%d %H:%M:%S\", \"%Y\"]`.\n",
    "\n",
    "We'll omit this added detail from our measurement configs for now in the interest of brevity, but see it added in at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbz2v3kgz83Y"
   },
   "source": [
    "##### **Disambiguating column references from string literals**\n",
    "We can see in the `gender` and `death` measurements that, in our conceptual specification, we sometimes used strings to refer to column names and sometimes as string literals. For the _code and time columns only_, the MESSY file disambiguates column references with `col(...)` and treats all others as string literals. String literals are only allowed for the `code` column; the `time` column can only accept `null` literals. So, we'll need to make some changes to these blocks to account for this (note that as we're making changes iteratively, they won't be fully valid until we're done). In some cases, it isn't clear how to make the change we're describing, so we'll add `???` indicators to those cases.\n",
    "\n",
    "```yaml\n",
    "gender: # We're all done with this format -- this block is complete!\n",
    "  code: col(gender)\n",
    "  time: null\n",
    "death:\n",
    "  code: MEDS_DEATH\n",
    "  time: ??? # dod @ 11:59 p.m.\n",
    "birth:\n",
    "  code: MEDS_BIRTH\n",
    "  time: ??? # anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "admission:\n",
    "  code: ??? # \"HOSPITAL_ADMISSION//${admission_type}//${admission_location}\"\n",
    "  time: col(admittime)\n",
    "death: # We're all done with this format -- this block is complete!\n",
    "  code: MEDS_DEATH\n",
    "  time: col(deathtime)\n",
    "procedure_icd:\n",
    "  code: ??? # \"PROCEDURE//ICD${icd_version}//${icd_code}\"\n",
    "  time: ??? # chartdate @ 11:59 p.m.\n",
    "  seq_num: seq_num # Note that this doesn't need a col(...) specifier\n",
    "chartevent:\n",
    "  code: ??? # \"CHARTEVENT//${itemid}//${valueuom}\"\n",
    "  time: col(charttime)\n",
    "  numeric_value: valuenum # Note that this doesn't need a col(...) specifier\n",
    "```\n",
    "\n",
    "Note that we can actually now see that in some cases, resolving this piece has \"completed\" a full block; `gender` and `death` are feature complete now, and can be omitted from the later sections for our tutorial pieces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6tiJpH55Ohz"
   },
   "source": [
    "##### **String interpolation in the code column**\n",
    "Another feature we see a lot of is string interpolation in the code column; e.g., `CHARTEVENT//${itemid}//${valueuom}`. How can we handle that?\n",
    "\n",
    "Unfortunately, as of now, the MEDS-Extract does not allow generit string interpolation; but it does allow you to specify a list of parts which will be concatenated together with the `//` separator. This is done just by specifying a list of each of the literals or columns (with the `col(...)` syntax to denote the latter) in the YAML file directly. Let's see it in action!\n",
    "\n",
    "```yaml\n",
    "death:\n",
    "  code: MEDS_DEATH\n",
    "  time: ??? # dod @ 11:59 p.m.\n",
    "birth:\n",
    "  code: MEDS_BIRTH\n",
    "  time: ??? # anchor_year - anchor_age @ Jan 1, 12:00:01 a.m.\n",
    "admission: # We're all done with this format -- this block is complete!\n",
    "  code:\n",
    "    - HOSPITAL_ADMISSION\n",
    "    - col(admission_type)\n",
    "    - col(admission_location)\n",
    "  time: col(admittime)\n",
    "procedure_icd:\n",
    "  code:\n",
    "    - PROCEDURE\n",
    "    - ??? #ICD${icd_version}\n",
    "    - col(icd_code)\n",
    "  time: ??? # chartdate @ 11:59 p.m.\n",
    "  seq_num: seq_num\n",
    "chartevent: # We're all done with this format -- this block is complete!\n",
    "  code:\n",
    "    - CHARTEVENT\n",
    "    - col(itemid)\n",
    "    - col(valueuom)\n",
    "  time: col(charttime)\n",
    "  numeric_value: valuenum\n",
    "```\n",
    "\n",
    "With this change, we've knocked out two blocks, but we see there is a tricky issue with a third -- the `procedure_icd` block doesn't support expressing things in the way we want. This is unfortunate, but for now it is unavoidable, so we'll have to change what we want the code string to be, and make the `ICD` part be separated from the version with another `//`:\n",
    "\n",
    "```yaml\n",
    "procedure_icd:\n",
    "  code:\n",
    "    - PROCEDURE\n",
    "    - ICD\n",
    "    - coi(icd_version)\n",
    "    - col(icd_code)\n",
    "  time: ??? # chartdate @ 11:59 p.m.\n",
    "  seq_num: seq_num\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FdQYl3X-Uls"
   },
   "source": [
    "##### **Timestamp Resolution and basic arithmetic**\n",
    "\n",
    "Now, we have a tricky one: in all remaining sources of uncertainty, we have one of two (or more) problems going on -- either (a) we need to resolve a timestamp to a specific time of day (e.g., `chartdate @ 11:59 p.m.`) or (b) we need to perform some simple arithmetic (e.g., `anchor_year - anchor_age`).\n",
    "\n",
    "MEDS-Extract does not currently support either of these operations. So, they need to happen in a \"pre-MEDS\" step, where we have some custom code go through and perform these operations for us on the raw dataframes, before we call MEDS-Extract. There are some other operations that might be required that MEDS-Extract can't handle currently that you should know about (even though we don't need them here), such as:\n",
    "  1. Joining multiple tables together to ensure the `subject_id` is present in all cases.\n",
    "  2. Adjusting \"offset\" time columns into true datetime columns (this is actually just a case of arithmetic and datetime parsing as well, but it warrants an explicit mention).\n",
    "  3. Any data filtering that needs to happen before MEDS extraction occurs (though often data cleaning can happen after the MEDS conversion process as well).\n",
    "\n",
    "Let's write a simple pre-MEDS step we can run here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyQ7KQ6F_dTH"
   },
   "source": [
    "##### **Pre-MEDS**\n",
    "\n",
    "Our Pre-MEDS step will have a few simple goals:\n",
    "  1. Subtract the anchor age from the anchor year to get a \"year of birth\"\n",
    "  2. Resolve the timestamps in `hosp/procedures_icd`.\n",
    "  3. Remove the duplication between the `dod` column in `hosp/patients` and the `deathtime` in `hosp/admissions` to favor the latter where both are specified.\n",
    "\n",
    "We'll write this using `pandas` for now, but you can use whatever method you want for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OOYdIPueAMFB"
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def get_year_of_birth(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  df[\"year_of_birth\"] = (\n",
    "      df[\"anchor_year\"].astype(int) - df[\"anchor_age\"].astype(int)\n",
    "  ).astype(str)\n",
    "  return df\n",
    "\n",
    "def put_procedure_at_EOD(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  df[\"chartdate\"] = (\n",
    "      pd.to_datetime(df[\"chartdate\"], format=\"%Y-%m-%d\") +\n",
    "      timedelta(hours=23, minutes=59, seconds=59)\n",
    "  )\n",
    "  return df\n",
    "\n",
    "def remove_dod_duplication_and_put_at_EOD(\n",
    "    patients_df: pd.DataFrame,\n",
    "    admissions_df: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "  subjects_with_deathtime = (\n",
    "      admissions_df[~admissions_df[\"deathtime\"].isna()][\"subject_id\"]\n",
    "  )\n",
    "\n",
    "  idx = patients_df[\"subject_id\"].isin(subjects_with_deathtime)\n",
    "  patients_df.loc[idx, \"dod\"] = None\n",
    "  patients_df[\"dod\"] = (\n",
    "      pd.to_datetime(patients_df[\"dod\"], format=\"%Y-%m-%d\") +\n",
    "      timedelta(hours=23, minutes=59, seconds=59)\n",
    "  )\n",
    "  return patients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fUUn6TNCKUa"
   },
   "source": [
    "We'll store the output of our pre-MEDS stage in an \"intermediate directory\" called `intermediate_dir` -- that way we can always re-use our raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCCGbrQACIMd"
   },
   "outputs": [],
   "source": [
    "INTERMEDIATE_DIR = Path(\"intermediate_dir\")\n",
    "\n",
    "for name, df in dfs.items():\n",
    "  if name == \"hosp/patients\":\n",
    "    df = get_year_of_birth(df)\n",
    "    df = remove_dod_duplication_and_put_at_EOD(df, dfs[\"hosp/admissions\"])\n",
    "  elif name == \"hosp/procedures_icd\":\n",
    "    df = put_procedure_at_EOD(df)\n",
    "\n",
    "  out_fp = INTERMEDIATE_DIR / f\"{name}.parquet\"\n",
    "  out_fp.parent.mkdir(parents=True, exist_ok=True)\n",
    "  df.to_parquet(out_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jc1GeTqNDV1U",
    "outputId": "be0046c5-42c2-44ce-b75c-5827cd1e2227"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tree intermediate_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "aWCSfZx1DYtT",
    "outputId": "0451402b-5df5-4542-bc45-2a400125cce1"
   },
   "outputs": [],
   "source": [
    "pd.read_parquet(INTERMEDIATE_DIR / \"hosp/patients.parquet\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xKnD5Fw8Dhtw",
    "outputId": "a73f1598-5db8-43d8-8e43-024cbeb39629"
   },
   "outputs": [],
   "source": [
    "pd.read_parquet(INTERMEDIATE_DIR / \"hosp/procedures_icd.parquet\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC6WYZ9RD5ch"
   },
   "source": [
    "##### **The final MESSY File**\n",
    "\n",
    "Now that we've resolved our remaining issues, let's put together our final, complete MESSY file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVyQ_qlmD_9z",
    "outputId": "e23c3221-5848-468e-d458-3eb268f67375"
   },
   "outputs": [],
   "source": [
    "YAML_contents = \"\"\"\n",
    "subject_id_col: subject_id\n",
    "hosp/patients:\n",
    "  gender:\n",
    "    code: col(gender)\n",
    "    time: null\n",
    "  death:\n",
    "    code: MEDS_DEATH\n",
    "    time: col(dod)\n",
    "  birth:\n",
    "    code: MEDS_BIRTH\n",
    "    time: col(year_of_birth)\n",
    "    time_format: \"%Y\"\n",
    "\n",
    "hosp/admissions:\n",
    "  ed_registration:\n",
    "    code: ED_REGISTRATION\n",
    "    time: col(edregtime)\n",
    "    time_format: \"%Y-%m-%d %H:%M:%S\"\n",
    "  ed_out:\n",
    "    code: ED_OUT\n",
    "    time: col(edouttime)\n",
    "    time_format: \"%Y-%m-%d %H:%M:%S\"\n",
    "  admission:\n",
    "    code:\n",
    "      - HOSPITAL_ADMISSION\n",
    "      - col(admission_type)\n",
    "      - col(admission_location)\n",
    "    time: col(admittime)\n",
    "    time_format: \"%Y-%m-%d %H:%M:%S\"\n",
    "    hadm_id: hadm_id\n",
    "  discharge:\n",
    "    code:\n",
    "      - HOSPITAL_DISCHARGE\n",
    "      - col(discharge_location)\n",
    "    time: col(dischtime)\n",
    "    time_format: \"%Y-%m-%d %H:%M:%S\"\n",
    "    hadm_id: hadm_id\n",
    "\n",
    "hosp/procedures_icd:\n",
    "  procedure_icd:\n",
    "    code:\n",
    "      - PROCEDURE\n",
    "      - ICD\n",
    "      - coi(icd_version)\n",
    "      - col(icd_code)\n",
    "    time: col(chartdate)\n",
    "    seq_num: seq_num\n",
    "\n",
    "icu/icustays:\n",
    "  admission:\n",
    "    code:\n",
    "      - ICU_ADMISSION\n",
    "      - col(first_careunit)\n",
    "    time: col(intime)\n",
    "    time_format: \"%Y-%m-%d %H:%M:%S\"\n",
    "  discharge:\n",
    "    code:\n",
    "      - ICU_DISCHARGE\n",
    "      - col(last_careunit)\n",
    "    time: col(outtime)\n",
    "    time_format: \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "icu/chartevents:\n",
    "  chartevent:\n",
    "    code:\n",
    "      - CHARTEVENT\n",
    "      - col(itemid)\n",
    "      - col(valueuom)\n",
    "    time: col(charttime)\n",
    "    time_format: \"%Y-%m-%d %H:%M:%S\"\n",
    "    numeric_value: valuenum\n",
    "\"\"\"\n",
    "\n",
    "YAML_fp = Path(\"MESSY.yaml\")\n",
    "YAML_fp.write_text(YAML_contents)\n",
    "print(YAML_fp.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCm7Dtm9-dHT"
   },
   "source": [
    "### Using the MESSY File -- how do you run MEDS-Extract?\n",
    "With the MESSY file specified, running MEDS-Extract is easy. There are two steps. First, install the package:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSq95ryE4ezz"
   },
   "outputs": [],
   "source": [
    "!pip --quiet install MEDS-extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1Zs7fLwG-bs"
   },
   "source": [
    "Next, use the [typical MEDS-Transforms syntax](https://github.com/mmcdermott/MEDS_transforms?tab=readme-ov-file#example-plugin-package) for running a dependent pipeline, and pass in the override variables you want. In our case, the command will look like the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIojljcCHCSe"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "MEDS_transform-pipeline \\\n",
    "    pkg://MEDS_extract.configs._extract.yaml \\\n",
    "    --overrides \\\n",
    "    input_dir=intermediate_dir \\\n",
    "    output_dir=output_dir \\\n",
    "    event_conversion_config_fp=MESSY.yaml \\\n",
    "    dataset.name=KDD_Tutorial \\\n",
    "    dataset.version=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQG1mgZfIkM1"
   },
   "source": [
    "If we've done things right, then we should see the above cell complete with no errors -- if we haven't, we'll need to debug. Thankfully, MEDS-Extract writes out some nice logs to help with this, which we can find in the output directory `output_dir`, under `output_dir/.logs/pipeline.log`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSa31u7eHR3c",
    "outputId": "65208f62-8c6c-4292-a808-87a1524c921e"
   },
   "outputs": [],
   "source": [
    "!cat output_dir/.logs/pipeline.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "szY7JN_aIwap"
   },
   "source": [
    "Note that if you did everything right, the log will still say `\"Command error:\"` at the end, with nothing following, which is reporting that there was _no_ error output written for the internal stages of the process.\n",
    "\n",
    "What do the output files themselves actually look like? Let's see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTjaBdlnHKNy",
    "outputId": "d3f80245-f782-4d2d-e855-37bb1b27c1ba"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tree output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ8V0tG9I7oB"
   },
   "source": [
    "There's a lot here -- thankfully, most of them are internal, partial outputs that MEDS-Extract writes so it can resume after failures on larger datasets. These aren't helpful for us, but are helpful when you're working with hundreds of thousands to billions of measurements!\n",
    "\n",
    "To see just the final files, we can look in the `data` and `metadata` sub-folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdRwjDvmJJuH",
    "outputId": "c8d15ca3-2f26-438e-9bc7-d6a70fefab73"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tree output_dir/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UV6XDBDEJMLW",
    "outputId": "b01eb2c7-fe9b-41ca-b496-f36bc9bf24f3"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "tree output_dir/metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmBHLAc6KHTp"
   },
   "source": [
    "### Going Forward\n",
    "While you've just built a great MEDS dataset over the MIMIC demo dataset in this tutorial, you've only looked at a small set of the included files we showed above. In the rest of the tutorial, we'll use the full MIMIC demo dataset, which we'll download as needed in the other notebooks, rather than the output of this notebook. Note that it also is built using a slightly different file than the one constructed here -- but rest assured, it is very similar to what you put together here. You can see how it is processed by looking at the dedicated [MIMIC-IV ETL Package](https://github.com/Medical-Event-Data-Standard/MIMIC_IV_MEDS/tree/main), or specifically the analogus [MESSY file used for all the sources](https://github.com/Medical-Event-Data-Standard/MIMIC_IV_MEDS/blob/main/src/MIMIC_IV_MEDS/configs/event_configs.yaml) in that repository!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlEQzjSXFz1i"
   },
   "source": [
    "### Additional Details and Resources\n",
    "\n",
    "You can also check out [MEDS-Extract's documentation](https://meds-extract.readthedocs.io/en/latest/) and [another example on synthetic data](https://github.com/mmcdermott/MEDS_extract/tree/main/example) via the included links as well!\n",
    "\n",
    "Even more importantly, what if you don't like MEDS-Extract and don't want to use it? Then don't! The three guiding questions of the extraction process (_What is happening?_, _To whom is it happening?_, and _When is it happening?_) can be turned into an extraction pipeline in whatever way you like -- the MEDS ecosystem is designed to be data-centric, so it doesn't matter how you got to a MEDS dataset, just that you did, and then tools can run from there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rafU3qeigoC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
